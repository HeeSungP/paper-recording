PS C:\Users\HEESUNG\workspace\0.pp\unet-rgb-master> python hs_model_v0_c.py
2021-09-22 20:10:34.290862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudart64_101.dll
(None, 512, 512, 1)
(None, 512, 512, 1)
2021-09-22 20:10:36.625085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library nvcuda.dll
2021-09-22 20:10:36.677639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with pr
operties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2021-09-22 20:10:36.691553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudart64_101.dll
2021-09-22 20:10:36.703708: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cublas64_10.dll
2021-09-22 20:10:36.716158: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cufft64_10.dll
2021-09-22 20:10:36.724024: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library curand64_10.dll
2021-09-22 20:10:36.734694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusolver64_10.dll
2021-09-22 20:10:36.747244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusparse64_10.dll
2021-09-22 20:10:36.767412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudnn64_7.dll
2021-09-22 20:10:36.774607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu dev
ices: 0
2021-09-22 20:10:36.791204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is
optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performa
nce-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-09-22 20:10:36.825102: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2001eaab080 ini
tialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-09-22 20:10:36.835209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0):
Host, Default Version
2021-09-22 20:10:36.840518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with pr
operties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2021-09-22 20:10:36.853940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudart64_101.dll
2021-09-22 20:10:36.862462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cublas64_10.dll
2021-09-22 20:10:36.868673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cufft64_10.dll
2021-09-22 20:10:36.875401: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library curand64_10.dll
2021-09-22 20:10:36.882501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusolver64_10.dll
2021-09-22 20:10:36.891226: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusparse64_10.dll
2021-09-22 20:10:36.910907: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudnn64_7.dll
2021-09-22 20:10:36.917322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu dev
ices: 0
2021-09-22 20:10:37.483710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect St
reamExecutor with strength 1 edge matrix:
2021-09-22 20:10:37.490684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2021-09-22 20:10:37.494997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2021-09-22 20:10:37.499215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow dev
ice (/job:localhost/replica:0/task:0/device:GPU:0 with 8678 MB memory) -> physical GPU (device: 0, name: Ge
Force GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2021-09-22 20:10:37.515338: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2004f23f000 ini
tialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-09-22 20:10:37.525555: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0):
GeForce GTX 1080 Ti, Compute Capability 6.1
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 512, 512, 1) 0
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 512, 512, 64) 640         input_1[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       conv2d[0][0]
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           conv2d_1[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      conv2d_2[0][0]
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_3[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      conv2d_4[0][0]
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_5[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     conv2d_6[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 64, 512)  0           conv2d_7[0][0]
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           dropout[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     conv2d_8[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 1024) 0           conv2d_9[0][0]
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 64, 64, 1024) 0           dropout_1[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 64, 64, 512)  2097664     up_sampling2d[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 64, 64, 1024) 0           dropout[0][0]
                                                                 conv2d_10[0][0]
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_11[0][0]
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 512 0           conv2d_12[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_5[0][0]
                                                                 conv2d_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 128, 128, 256 590080      conv2d_14[0][0]
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 256 0           conv2d_15[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 256, 256, 128 131200      up_sampling2d_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_3[0][0]
                                                                 conv2d_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 256, 256, 128 147584      conv2d_17[0][0]
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_18[0][0]
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 512, 512, 64) 32832       up_sampling2d_3[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_1[0][0]
                                                                 conv2d_19[0][0]
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_20[0][0]
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 512, 512, 2)  1154        conv2d_21[0][0]
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 512, 512, 1) 0
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 512, 512, 1)  3           conv2d_22[0][0]
==================================================================================================
Total params: 31,031,685
Trainable params: 31,031,685
Non-trainable params: 0
__________________________________________________________________________________________________
loading data
load train images...
------------------------------
load test images...
------------------------------
loading data done
(None, 512, 512, 1)
(None, 512, 512, 1)
got unet
Fitting model...
Epoch 1/50
2021-09-22 20:10:40.813369: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudnn64_7.dll
2021-09-22 20:10:41.570141: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking G
PU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-09-22 20:10:41.630582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cublas64_10.dll
  2/122 [..............................] - ETA: 31s - loss: 0.7129 - accuracy: 0.4985WARNING:tensorflow:Cal
lbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1695s vs `on_train_bat
ch_end` time: 0.3530s). Check your callbacks.
122/122 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.7479
Epoch 00001: loss improved from inf to 0.67576, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 70s 571ms/step - loss: 0.6758 - accuracy: 0.7479 - val_loss: 0.6
608 - val_accuracy: 0.7802
Epoch 2/50
122/122 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.7311
Epoch 00002: loss did not improve from 0.67576
122/122 [==============================] - 67s 546ms/step - loss: 0.6953 - accuracy: 0.7311 - val_loss: 0.6
778 - val_accuracy: 0.7276
Epoch 3/50
122/122 [==============================] - ETA: 0s - loss: 0.6730 - accuracy: 0.7404
Epoch 00003: loss improved from 0.67576 to 0.67295, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 67s 548ms/step - loss: 0.6730 - accuracy: 0.7404 - val_loss: 0.6
731 - val_accuracy: 0.7316
Epoch 4/50
122/122 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.7367
Epoch 00004: loss did not improve from 0.67295
122/122 [==============================] - 66s 538ms/step - loss: 0.6738 - accuracy: 0.7367 - val_loss: 0.6
799 - val_accuracy: 0.7159
Epoch 5/50
122/122 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.7217
Epoch 00005: loss did not improve from 0.67295
122/122 [==============================] - 66s 538ms/step - loss: 0.6785 - accuracy: 0.7217 - val_loss: 0.6
786 - val_accuracy: 0.7141
Epoch 6/50
122/122 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.7173
Epoch 00006: loss did not improve from 0.67295
122/122 [==============================] - 66s 540ms/step - loss: 0.6787 - accuracy: 0.7173 - val_loss: 0.6
774 - val_accuracy: 0.7122
Epoch 7/50
122/122 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.7173
Epoch 00007: loss did not improve from 0.67295
122/122 [==============================] - 66s 538ms/step - loss: 0.6762 - accuracy: 0.7173 - val_loss: 0.6
742 - val_accuracy: 0.7140
Epoch 8/50
122/122 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.7178
Epoch 00008: loss did not improve from 0.67295
122/122 [==============================] - 66s 541ms/step - loss: 0.6737 - accuracy: 0.7178 - val_loss: 0.6
731 - val_accuracy: 0.7122
Epoch 9/50
122/122 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.7172
Epoch 00009: loss improved from 0.67295 to 0.67175, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 67s 546ms/step - loss: 0.6718 - accuracy: 0.7172 - val_loss: 0.6
710 - val_accuracy: 0.7122
Epoch 10/50
122/122 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.7173
Epoch 00010: loss improved from 0.67175 to 0.66956, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 544ms/step - loss: 0.6696 - accuracy: 0.7173 - val_loss: 0.6
689 - val_accuracy: 0.7122
Epoch 11/50
122/122 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.7173
Epoch 00011: loss improved from 0.66956 to 0.66742, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 543ms/step - loss: 0.6674 - accuracy: 0.7173 - val_loss: 0.6
668 - val_accuracy: 0.7122
Epoch 12/50
122/122 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.7173
Epoch 00012: loss improved from 0.66742 to 0.66532, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 67s 548ms/step - loss: 0.6653 - accuracy: 0.7173 - val_loss: 0.6
648 - val_accuracy: 0.7122
Epoch 13/50
122/122 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.7173
Epoch 00013: loss improved from 0.66532 to 0.66325, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 544ms/step - loss: 0.6633 - accuracy: 0.7173 - val_loss: 0.6
628 - val_accuracy: 0.7123
Epoch 14/50
122/122 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.7176
Epoch 00014: loss did not improve from 0.66325
122/122 [==============================] - 66s 537ms/step - loss: 0.6731 - accuracy: 0.7176 - val_loss: 0.6
610 - val_accuracy: 0.7122
Epoch 15/50
122/122 [==============================] - ETA: 0s - loss: 0.6607 - accuracy: 0.7208
Epoch 00015: loss improved from 0.66325 to 0.66075, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 545ms/step - loss: 0.6607 - accuracy: 0.7208 - val_loss: 0.6
603 - val_accuracy: 0.7103
Epoch 16/50
122/122 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.7154
Epoch 00016: loss improved from 0.66075 to 0.65864, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 544ms/step - loss: 0.6586 - accuracy: 0.7154 - val_loss: 0.6
585 - val_accuracy: 0.7103
Epoch 17/50
122/122 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 0.7154
Epoch 00017: loss improved from 0.65864 to 0.65676, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 544ms/step - loss: 0.6568 - accuracy: 0.7154 - val_loss: 0.6
567 - val_accuracy: 0.7103
Epoch 18/50
122/122 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.7154
Epoch 00018: loss improved from 0.65676 to 0.65492, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 543ms/step - loss: 0.6549 - accuracy: 0.7154 - val_loss: 0.6
549 - val_accuracy: 0.7103
Epoch 19/50
122/122 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.7154
Epoch 00019: loss improved from 0.65492 to 0.65311, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 541ms/step - loss: 0.6531 - accuracy: 0.7154 - val_loss: 0.6
532 - val_accuracy: 0.7103
Epoch 20/50
122/122 [==============================] - ETA: 0s - loss: 0.6513 - accuracy: 0.7154
Epoch 00020: loss improved from 0.65311 to 0.65134, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6513 - accuracy: 0.7154 - val_loss: 0.6
514 - val_accuracy: 0.7103
Epoch 21/50
122/122 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.7154
Epoch 00021: loss improved from 0.65134 to 0.64959, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6496 - accuracy: 0.7154 - val_loss: 0.6
498 - val_accuracy: 0.7103
Epoch 22/50
122/122 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.7154
Epoch 00022: loss improved from 0.64959 to 0.64788, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6479 - accuracy: 0.7154 - val_loss: 0.6
481 - val_accuracy: 0.7103
Epoch 23/50
122/122 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7154
Epoch 00023: loss improved from 0.64788 to 0.64620, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 543ms/step - loss: 0.6462 - accuracy: 0.7154 - val_loss: 0.6
465 - val_accuracy: 0.7103
Epoch 24/50
122/122 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7154
Epoch 00024: loss improved from 0.64620 to 0.64455, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6445 - accuracy: 0.7154 - val_loss: 0.6
449 - val_accuracy: 0.7103
Epoch 25/50
122/122 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.7154
Epoch 00025: loss improved from 0.64455 to 0.64293, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6429 - accuracy: 0.7154 - val_loss: 0.6
434 - val_accuracy: 0.7103
Epoch 26/50
122/122 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.7154
Epoch 00026: loss improved from 0.64293 to 0.64135, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6413 - accuracy: 0.7154 - val_loss: 0.6
418 - val_accuracy: 0.7103
Epoch 27/50
122/122 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.7154
Epoch 00027: loss improved from 0.64135 to 0.63979, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6398 - accuracy: 0.7154 - val_loss: 0.6
404 - val_accuracy: 0.7103
Epoch 28/50
122/122 [==============================] - ETA: 0s - loss: 0.6383 - accuracy: 0.7154
Epoch 00028: loss improved from 0.63979 to 0.63827, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6383 - accuracy: 0.7154 - val_loss: 0.6
389 - val_accuracy: 0.7103
Epoch 29/50
122/122 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.7154
Epoch 00029: loss improved from 0.63827 to 0.63678, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 543ms/step - loss: 0.6368 - accuracy: 0.7154 - val_loss: 0.6
375 - val_accuracy: 0.7103
Epoch 30/50
122/122 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.7154
Epoch 00030: loss improved from 0.63678 to 0.63532, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 68s 555ms/step - loss: 0.6353 - accuracy: 0.7154 - val_loss: 0.6
361 - val_accuracy: 0.7103
Epoch 31/50
122/122 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.7154
Epoch 00031: loss improved from 0.63532 to 0.63388, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 67s 549ms/step - loss: 0.6339 - accuracy: 0.7154 - val_loss: 0.6
347 - val_accuracy: 0.7103
Epoch 32/50
122/122 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.7154
Epoch 00032: loss improved from 0.63388 to 0.63249, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 544ms/step - loss: 0.6325 - accuracy: 0.7154 - val_loss: 0.6
334 - val_accuracy: 0.7103
Epoch 33/50
122/122 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.7154
Epoch 00033: loss improved from 0.63249 to 0.63112, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 544ms/step - loss: 0.6311 - accuracy: 0.7154 - val_loss: 0.6
320 - val_accuracy: 0.7103
Epoch 34/50
122/122 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.7154
Epoch 00034: loss improved from 0.63112 to 0.62978, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 67s 547ms/step - loss: 0.6298 - accuracy: 0.7154 - val_loss: 0.6
308 - val_accuracy: 0.7103
Epoch 35/50
122/122 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.7154
Epoch 00035: loss improved from 0.62978 to 0.62847, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 545ms/step - loss: 0.6285 - accuracy: 0.7154 - val_loss: 0.6
295 - val_accuracy: 0.7103
Epoch 36/50
122/122 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.7154
Epoch 00036: loss improved from 0.62847 to 0.62720, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 67s 546ms/step - loss: 0.6272 - accuracy: 0.7154 - val_loss: 0.6
283 - val_accuracy: 0.7103
Epoch 37/50
122/122 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.7154
Epoch 00037: loss improved from 0.62720 to 0.62595, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6260 - accuracy: 0.7154 - val_loss: 0.6
271 - val_accuracy: 0.7103
Epoch 38/50
122/122 [==============================] - ETA: 0s - loss: 0.6247 - accuracy: 0.7154
Epoch 00038: loss improved from 0.62595 to 0.62473, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6247 - accuracy: 0.7154 - val_loss: 0.6
260 - val_accuracy: 0.7103
Epoch 39/50
122/122 [==============================] - ETA: 0s - loss: 0.6235 - accuracy: 0.7154
Epoch 00039: loss improved from 0.62473 to 0.62355, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6235 - accuracy: 0.7154 - val_loss: 0.6
248 - val_accuracy: 0.7103
Epoch 40/50
122/122 [==============================] - ETA: 0s - loss: 0.6224 - accuracy: 0.7154
Epoch 00040: loss improved from 0.62355 to 0.62239, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6224 - accuracy: 0.7154 - val_loss: 0.6
237 - val_accuracy: 0.7103
Epoch 41/50
122/122 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.7154
Epoch 00041: loss improved from 0.62239 to 0.62125, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6212 - accuracy: 0.7154 - val_loss: 0.6
226 - val_accuracy: 0.7103
Epoch 42/50
122/122 [==============================] - ETA: 0s - loss: 0.6201 - accuracy: 0.7154
Epoch 00042: loss improved from 0.62125 to 0.62015, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6201 - accuracy: 0.7154 - val_loss: 0.6
216 - val_accuracy: 0.7103
Epoch 43/50
122/122 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.7154
Epoch 00043: loss improved from 0.62015 to 0.61907, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6191 - accuracy: 0.7154 - val_loss: 0.6
206 - val_accuracy: 0.7103
Epoch 44/50
122/122 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.7154
Epoch 00044: loss improved from 0.61907 to 0.61802, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6180 - accuracy: 0.7154 - val_loss: 0.6
196 - val_accuracy: 0.7103
Epoch 45/50
122/122 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.7154
Epoch 00045: loss improved from 0.61802 to 0.61699, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6170 - accuracy: 0.7154 - val_loss: 0.6
186 - val_accuracy: 0.7103
Epoch 46/50
122/122 [==============================] - ETA: 0s - loss: 0.6160 - accuracy: 0.7154
Epoch 00046: loss improved from 0.61699 to 0.61600, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6160 - accuracy: 0.7154 - val_loss: 0.6
177 - val_accuracy: 0.7103
Epoch 47/50
122/122 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.7154
Epoch 00047: loss improved from 0.61600 to 0.61503, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6150 - accuracy: 0.7154 - val_loss: 0.6
168 - val_accuracy: 0.7103
Epoch 48/50
122/122 [==============================] - ETA: 0s - loss: 0.6141 - accuracy: 0.7154
Epoch 00048: loss improved from 0.61503 to 0.61408, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6141 - accuracy: 0.7154 - val_loss: 0.6
159 - val_accuracy: 0.7103
Epoch 49/50
122/122 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.7154
Epoch 00049: loss improved from 0.61408 to 0.61317, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6132 - accuracy: 0.7154 - val_loss: 0.6
150 - val_accuracy: 0.7103
Epoch 50/50
122/122 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.7154
Epoch 00050: loss improved from 0.61317 to 0.61227, saving model to ./weights\hs_v0_c_unet.hdf5
122/122 [==============================] - 66s 542ms/step - loss: 0.6123 - accuracy: 0.7154 - val_loss: 0.6
142 - val_accuracy: 0.7103
predict test data
test candidate data : (20, 512, 512, 1)
 1/20 [>.............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end`
is slow compared to the batch time (batch time: 0.0030s vs `on_predict_batch_end` time: 0.0399s). Check you
r callbacks.
20/20 [==============================] - 1s 41ms/step
test result data : (20, 512, 512, 1)
array to image