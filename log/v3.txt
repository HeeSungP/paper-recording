PS C:\Users\HEESUNG\workspace\0.pp\unet-rgb-master> python hs_model_v3.py
2021-09-22 13:51:09.885996: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cudart64_101.dll
Creating training images...
540 540
C:\Users\HEESUNG\anaconda3\envs\tf_keras\lib\site-packages\keras_preprocessing\image\utils.py:107: UserWar
ning: grayscale is deprecated. Please use color_mode = "grayscale"
  warnings.warn('grayscale is deprecated. Please use '
Done: 0/540 images
Done: 60/540 images
Done: 120/540 images
Done: 180/540 images
Done: 240/540 images
Done: 300/540 images
Done: 360/540 images
Done: 420/540 images
Done: 480/540 images
loading done
Saving to .npy files done.
Creating test images...
loading done
Saving to imgs_test.npy files done.
(None, 512, 512, 2)
(None, 512, 512, 1)
2021-09-22 13:51:21.506061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library nvcuda.dll
2021-09-22 13:51:21.538787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with p
roperties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2021-09-22 13:51:21.552951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cudart64_101.dll
2021-09-22 13:51:21.563903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cublas64_10.dll
2021-09-22 13:51:21.575343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cufft64_10.dll
2021-09-22 13:51:21.583797: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library curand64_10.dll
2021-09-22 13:51:21.594990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cusolver64_10.dll
2021-09-22 13:51:21.604668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cusparse64_10.dll
2021-09-22 13:51:21.628717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cudnn64_7.dll
2021-09-22 13:51:21.635088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu de
vices: 0
2021-09-22 13:51:21.640164: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is
 optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in perfor
mance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-09-22 13:51:21.661669: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x241fed36cc0 in
itialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-09-22 13:51:21.670628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0):
 Host, Default Version
2021-09-22 13:51:21.677891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with p
roperties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2021-09-22 13:51:21.695043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cudart64_101.dll
2021-09-22 13:51:21.702490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cublas64_10.dll
2021-09-22 13:51:21.709115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cufft64_10.dll
2021-09-22 13:51:21.715556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library curand64_10.dll
2021-09-22 13:51:21.724946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cusolver64_10.dll
2021-09-22 13:51:21.731693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cusparse64_10.dll
2021-09-22 13:51:21.741613: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cudnn64_7.dll
2021-09-22 13:51:21.750537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu de
vices: 0
2021-09-22 13:51:22.313368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect S
treamExecutor with strength 1 edge matrix:
2021-09-22 13:51:22.320622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2021-09-22 13:51:22.324639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2021-09-22 13:51:22.328541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow de
vice (/job:localhost/replica:0/task:0/device:GPU:0 with 8678 MB memory) -> physical GPU (device: 0, name:
GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2021-09-22 13:51:22.343099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x241a65a3b70 in
itialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-09-22 13:51:22.353036: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0):
 GeForce GTX 1080 Ti, Compute Capability 6.1
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 512, 512, 2) 0
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 512, 512, 64) 1216        input_1[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       conv2d[0][0]
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           conv2d_1[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      conv2d_2[0][0]
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_3[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      conv2d_4[0][0]
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_5[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     conv2d_6[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 64, 512)  0           conv2d_7[0][0]
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           dropout[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     conv2d_8[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 1024) 0           conv2d_9[0][0]
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 64, 64, 1024) 0           dropout_1[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 64, 64, 512)  2097664     up_sampling2d[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 64, 64, 1024) 0           dropout[0][0]
                                                                 conv2d_10[0][0]
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_11[0][0]
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 512 0           conv2d_12[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_5[0][0]
                                                                 conv2d_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 128, 128, 256 590080      conv2d_14[0][0]
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 256 0           conv2d_15[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 256, 256, 128 131200      up_sampling2d_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_3[0][0]
                                                                 conv2d_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 256, 256, 128 147584      conv2d_17[0][0]
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_18[0][0]
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 512, 512, 64) 32832       up_sampling2d_3[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_1[0][0]
                                                                 conv2d_19[0][0]
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_20[0][0]
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 512, 512, 2)  1154        conv2d_21[0][0]
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 512, 512, 1) 0
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 512, 512, 3)  0           conv2d_22[0][0]
                                                                 input_2[0][0]
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 512, 512, 2)  56          concatenate_4[0][0]
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 512, 512, 1)  19          conv2d_23[0][0]
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 512, 512, 1)  2           conv2d_24[0][0]
==================================================================================================
Total params: 31,032,335
Trainable params: 31,032,335
Non-trainable params: 0
__________________________________________________________________________________________________
loading data
load train images...
------------------------------
load test images...
------------------------------
loading data done
(None, 512, 512, 2)
(None, 512, 512, 1)
got unet
Fitting model...
Epoch 1/50
2021-09-22 13:51:26.100852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cudnn64_7.dll
2021-09-22 13:51:26.811933: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking
GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-09-22 13:51:26.864397: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully o
pened dynamic library cublas64_10.dll
  2/486 [..............................] - ETA: 36s - loss: 0.7134 - accuracy: 0.5927WARNING:tensorflow:Ca
llbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_b
atch_end` time: 0.1436s). Check your callbacks.
486/486 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.7298WARNING:tensorflow:Cal
lbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batc
h_end` time: 0.0389s). Check your callbacks.

Epoch 00001: loss improved from inf to 0.68119, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.6812 - accuracy: 0.7298 - val_loss: 0.
6632 - val_accuracy: 0.7557
Epoch 2/50
486/486 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.7804
Epoch 00002: loss improved from 0.68119 to 0.64404, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 159ms/step - loss: 0.6440 - accuracy: 0.7804 - val_loss: 0.
6191 - val_accuracy: 0.8038
Epoch 3/50
486/486 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.8438
Epoch 00003: loss improved from 0.64404 to 0.60183, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.6018 - accuracy: 0.8438 - val_loss: 0.
5792 - val_accuracy: 0.8742
Epoch 4/50
486/486 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.8747
Epoch 00004: loss improved from 0.60183 to 0.56362, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.5636 - accuracy: 0.8747 - val_loss: 0.
6070 - val_accuracy: 0.8129
Epoch 5/50
486/486 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.8798
Epoch 00005: loss improved from 0.56362 to 0.54713, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.5471 - accuracy: 0.8798 - val_loss: 0.
5129 - val_accuracy: 0.9047
Epoch 6/50
486/486 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.9314
Epoch 00006: loss improved from 0.54713 to 0.48119, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.4812 - accuracy: 0.9314 - val_loss: 0.
4760 - val_accuracy: 0.9267
Epoch 7/50
486/486 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.9365
Epoch 00007: loss improved from 0.48119 to 0.46000, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.4600 - accuracy: 0.9365 - val_loss: 0.
4952 - val_accuracy: 0.9111
Epoch 8/50
486/486 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.9325
Epoch 00008: loss improved from 0.46000 to 0.45323, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.4532 - accuracy: 0.9325 - val_loss: 0.
4436 - val_accuracy: 0.9314
Epoch 9/50
486/486 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.9415
Epoch 00009: loss improved from 0.45323 to 0.42845, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.4285 - accuracy: 0.9415 - val_loss: 0.
4270 - val_accuracy: 0.9350
Epoch 10/50
486/486 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.9429
Epoch 00010: loss improved from 0.42845 to 0.41376, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.4138 - accuracy: 0.9429 - val_loss: 0.
4162 - val_accuracy: 0.9351
Epoch 11/50
486/486 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.9423
Epoch 00011: loss improved from 0.41376 to 0.40354, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 159ms/step - loss: 0.4035 - accuracy: 0.9423 - val_loss: 0.
4115 - val_accuracy: 0.9263
Epoch 12/50
486/486 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.9444
Epoch 00012: loss improved from 0.40354 to 0.38922, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 78s 160ms/step - loss: 0.3892 - accuracy: 0.9444 - val_loss: 0.
3862 - val_accuracy: 0.9413
Epoch 13/50
486/486 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.9434
Epoch 00013: loss improved from 0.38922 to 0.38054, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 159ms/step - loss: 0.3805 - accuracy: 0.9434 - val_loss: 0.
3825 - val_accuracy: 0.9364
Epoch 14/50
486/486 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.9456
Epoch 00014: loss improved from 0.38054 to 0.36757, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 159ms/step - loss: 0.3676 - accuracy: 0.9456 - val_loss: 0.
3611 - val_accuracy: 0.9460
Epoch 15/50
486/486 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.9474
Epoch 00015: loss improved from 0.36757 to 0.35539, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.3554 - accuracy: 0.9474 - val_loss: 0.
3585 - val_accuracy: 0.9383
Epoch 16/50
486/486 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.9478
Epoch 00016: loss improved from 0.35539 to 0.34540, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.3454 - accuracy: 0.9478 - val_loss: 0.
3413 - val_accuracy: 0.9450
Epoch 17/50
486/486 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.9487
Epoch 00017: loss improved from 0.34540 to 0.33490, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.3349 - accuracy: 0.9487 - val_loss: 0.
3350 - val_accuracy: 0.9437
Epoch 18/50
486/486 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.9501
Epoch 00018: loss improved from 0.33490 to 0.32469, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.3247 - accuracy: 0.9501 - val_loss: 0.
3231 - val_accuracy: 0.9471
Epoch 19/50
486/486 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.9502
Epoch 00019: loss improved from 0.32469 to 0.31542, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 81s 167ms/step - loss: 0.3154 - accuracy: 0.9502 - val_loss: 0.
3171 - val_accuracy: 0.9441
Epoch 20/50
486/486 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.9516
Epoch 00020: loss improved from 0.31542 to 0.30469, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.3047 - accuracy: 0.9516 - val_loss: 0.
3018 - val_accuracy: 0.9501
Epoch 21/50
486/486 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.9516
Epoch 00021: loss improved from 0.30469 to 0.29725, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2972 - accuracy: 0.9516 - val_loss: 0.
2977 - val_accuracy: 0.9489
Epoch 22/50
486/486 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.9528
Epoch 00022: loss improved from 0.29725 to 0.28714, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2871 - accuracy: 0.9528 - val_loss: 0.
2926 - val_accuracy: 0.9448
Epoch 23/50
486/486 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.9520
Epoch 00023: loss improved from 0.28714 to 0.28126, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2813 - accuracy: 0.9520 - val_loss: 0.
2803 - val_accuracy: 0.9493
Epoch 24/50
486/486 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9525
Epoch 00024: loss improved from 0.28126 to 0.27359, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2736 - accuracy: 0.9525 - val_loss: 0.
2758 - val_accuracy: 0.9477
Epoch 25/50
486/486 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9555
Epoch 00025: loss improved from 0.27359 to 0.26109, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2611 - accuracy: 0.9555 - val_loss: 0.
2650 - val_accuracy: 0.9502
Epoch 26/50
486/486 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.9556
Epoch 00026: loss improved from 0.26109 to 0.25425, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2543 - accuracy: 0.9556 - val_loss: 0.
2618 - val_accuracy: 0.9479
Epoch 27/50
486/486 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.9560
Epoch 00027: loss improved from 0.25425 to 0.24682, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.2468 - accuracy: 0.9560 - val_loss: 0.
2522 - val_accuracy: 0.9498
Epoch 28/50
486/486 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9559
Epoch 00028: loss improved from 0.24682 to 0.24100, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 81s 166ms/step - loss: 0.2410 - accuracy: 0.9559 - val_loss: 0.
2490 - val_accuracy: 0.9494
Epoch 29/50
486/486 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.9563
Epoch 00029: loss improved from 0.24100 to 0.23395, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2340 - accuracy: 0.9563 - val_loss: 0.
2381 - val_accuracy: 0.9509
Epoch 30/50
486/486 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9579
Epoch 00030: loss improved from 0.23395 to 0.22538, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2254 - accuracy: 0.9579 - val_loss: 0.
2418 - val_accuracy: 0.9464
Epoch 31/50
486/486 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9585
Epoch 00031: loss improved from 0.22538 to 0.21844, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.2184 - accuracy: 0.9585 - val_loss: 0.
2281 - val_accuracy: 0.9518
Epoch 32/50
486/486 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9596
Epoch 00032: loss improved from 0.21844 to 0.21075, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.2107 - accuracy: 0.9596 - val_loss: 0.
2201 - val_accuracy: 0.9519
Epoch 33/50
486/486 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9598
Epoch 00033: loss improved from 0.21075 to 0.20486, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.2049 - accuracy: 0.9598 - val_loss: 0.
2173 - val_accuracy: 0.9523
Epoch 34/50
486/486 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9601
Epoch 00034: loss improved from 0.20486 to 0.19990, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.1999 - accuracy: 0.9601 - val_loss: 0.
2128 - val_accuracy: 0.9507
Epoch 35/50
486/486 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9613
Epoch 00035: loss improved from 0.19990 to 0.19291, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.1929 - accuracy: 0.9613 - val_loss: 0.
2073 - val_accuracy: 0.9516
Epoch 36/50
486/486 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9596
Epoch 00036: loss improved from 0.19291 to 0.19247, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 81s 166ms/step - loss: 0.1925 - accuracy: 0.9596 - val_loss: 0.
2073 - val_accuracy: 0.9536
Epoch 37/50
486/486 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9617
Epoch 00037: loss improved from 0.19247 to 0.18305, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.1831 - accuracy: 0.9617 - val_loss: 0.
2054 - val_accuracy: 0.9487
Epoch 38/50
486/486 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9625
Epoch 00038: loss improved from 0.18305 to 0.17710, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 81s 166ms/step - loss: 0.1771 - accuracy: 0.9625 - val_loss: 0.
1925 - val_accuracy: 0.9543
Epoch 39/50
486/486 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9636
Epoch 00039: loss improved from 0.17710 to 0.17055, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 165ms/step - loss: 0.1705 - accuracy: 0.9636 - val_loss: 0.
1884 - val_accuracy: 0.9542
Epoch 40/50
486/486 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9631
Epoch 00040: loss improved from 0.17055 to 0.16847, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 81s 166ms/step - loss: 0.1685 - accuracy: 0.9631 - val_loss: 0.
1874 - val_accuracy: 0.9544
Epoch 41/50
486/486 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9654
Epoch 00041: loss improved from 0.16847 to 0.15928, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 81s 167ms/step - loss: 0.1593 - accuracy: 0.9654 - val_loss: 0.
1849 - val_accuracy: 0.9520
Epoch 42/50
486/486 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.9644
Epoch 00042: loss improved from 0.15928 to 0.15832, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 81s 168ms/step - loss: 0.1583 - accuracy: 0.9644 - val_loss: 0.
1772 - val_accuracy: 0.9533
Epoch 43/50
486/486 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9654
Epoch 00043: loss improved from 0.15832 to 0.15216, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 80s 164ms/step - loss: 0.1522 - accuracy: 0.9654 - val_loss: 0.
1674 - val_accuracy: 0.9569
Epoch 44/50
486/486 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.9679
Epoch 00044: loss improved from 0.15216 to 0.14367, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.1437 - accuracy: 0.9679 - val_loss: 0.
1703 - val_accuracy: 0.9553
Epoch 45/50
486/486 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9680
Epoch 00045: loss improved from 0.14367 to 0.14016, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.1402 - accuracy: 0.9680 - val_loss: 0.
1655 - val_accuracy: 0.9563
Epoch 46/50
486/486 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9690
Epoch 00046: loss improved from 0.14016 to 0.13489, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.1349 - accuracy: 0.9690 - val_loss: 0.
1586 - val_accuracy: 0.9580
Epoch 47/50
486/486 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9701
Epoch 00047: loss improved from 0.13489 to 0.12969, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 159ms/step - loss: 0.1297 - accuracy: 0.9701 - val_loss: 0.
1558 - val_accuracy: 0.9586
Epoch 48/50
486/486 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9687
Epoch 00048: loss did not improve from 0.12969
486/486 [==============================] - 76s 157ms/step - loss: 0.1301 - accuracy: 0.9687 - val_loss: 0.
1567 - val_accuracy: 0.9554
Epoch 49/50
486/486 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9705
Epoch 00049: loss improved from 0.12969 to 0.12316, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.1232 - accuracy: 0.9705 - val_loss: 0.
1530 - val_accuracy: 0.9566
Epoch 50/50
486/486 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9711
Epoch 00050: loss improved from 0.12316 to 0.11901, saving model to ./weights\hs_v3_unet.hdf5
486/486 [==============================] - 77s 158ms/step - loss: 0.1190 - accuracy: 0.9711 - val_loss: 0.
1452 - val_accuracy: 0.9590
predict test data
test candidate data : (20, 512, 512, 2)
 1/20 [>.............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end`
 is slow compared to the batch time (batch time: 0.0040s vs `on_predict_batch_end` time: 0.0409s). Check y
our callbacks.
20/20 [==============================] - 1s 44ms/step
test result data : (20, 512, 512, 1)
array to image
PS C:\Users\HEESUNG\workspace\0.pp\unet-rgb-master>