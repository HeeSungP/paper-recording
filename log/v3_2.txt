PS C:\Users\HEESUNG\workspace\0.pp\unet-rgb-master> python hs_model_v3.py
2021-09-22 17:43:14.322886: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudart64_101.dll
Creating training images...
540 540
C:\Users\HEESUNG\anaconda3\envs\tf_keras\lib\site-packages\keras_preprocessing\image\utils.py:107: UserWarn
ing: grayscale is deprecated. Please use color_mode = "grayscale"
  warnings.warn('grayscale is deprecated. Please use '
Done: 0/540 images
Done: 60/540 images
Done: 120/540 images
Done: 180/540 images
Done: 240/540 images
Done: 300/540 images
Done: 360/540 images
Done: 420/540 images
Done: 480/540 images
loading done
Saving to .npy files done.
Creating test images...
loading done
Saving to imgs_test.npy files done.
(None, 512, 512, 2)
(None, 512, 512, 1)
2021-09-22 17:43:27.337936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library nvcuda.dll
2021-09-22 17:43:27.369215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with pr
operties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2021-09-22 17:43:27.383396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudart64_101.dll
2021-09-22 17:43:27.395056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cublas64_10.dll
2021-09-22 17:43:27.429335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cufft64_10.dll
2021-09-22 17:43:27.438201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library curand64_10.dll
2021-09-22 17:43:27.448483: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusolver64_10.dll
2021-09-22 17:43:27.458160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusparse64_10.dll
2021-09-22 17:43:27.474786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudnn64_7.dll
2021-09-22 17:43:27.480704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu dev
ices: 0
2021-09-22 17:43:27.487774: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is
optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performa
nce-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-09-22 17:43:27.510566: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a603e57f50 ini
tialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-09-22 17:43:27.521495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0):
Host, Default Version
2021-09-22 17:43:27.527247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with pr
operties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2021-09-22 17:43:27.565478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudart64_101.dll
2021-09-22 17:43:27.572920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cublas64_10.dll
2021-09-22 17:43:27.581378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cufft64_10.dll
2021-09-22 17:43:27.589589: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library curand64_10.dll
2021-09-22 17:43:27.595466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusolver64_10.dll
2021-09-22 17:43:27.602564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cusparse64_10.dll
2021-09-22 17:43:27.610519: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudnn64_7.dll
2021-09-22 17:43:27.618395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu dev
ices: 0
2021-09-22 17:43:28.261526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect St
reamExecutor with strength 1 edge matrix:
2021-09-22 17:43:28.273262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2021-09-22 17:43:28.277560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2021-09-22 17:43:28.285311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow dev
ice (/job:localhost/replica:0/task:0/device:GPU:0 with 8678 MB memory) -> physical GPU (device: 0, name: Ge
Force GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2021-09-22 17:43:28.306503: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a639912810 ini
tialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-09-22 17:43:28.341798: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0):
GeForce GTX 1080 Ti, Compute Capability 6.1
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 512, 512, 2) 0
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 512, 512, 64) 1216        input_1[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       conv2d[0][0]
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           conv2d_1[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      conv2d_2[0][0]
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_3[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      conv2d_4[0][0]
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_5[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     conv2d_6[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 64, 512)  0           conv2d_7[0][0]
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           dropout[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     conv2d_8[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 1024) 0           conv2d_9[0][0]
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 64, 64, 1024) 0           dropout_1[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 64, 64, 512)  2097664     up_sampling2d[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 64, 64, 1024) 0           dropout[0][0]
                                                                 conv2d_10[0][0]
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_11[0][0]
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 512 0           conv2d_12[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_5[0][0]
                                                                 conv2d_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 128, 128, 256 590080      conv2d_14[0][0]
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 256 0           conv2d_15[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 256, 256, 128 131200      up_sampling2d_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_3[0][0]
                                                                 conv2d_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 256, 256, 128 147584      conv2d_17[0][0]
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_18[0][0]
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 512, 512, 64) 32832       up_sampling2d_3[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_1[0][0]
                                                                 conv2d_19[0][0]
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_20[0][0]
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 512, 512, 2)  1154        conv2d_21[0][0]
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 512, 512, 1) 0
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 512, 512, 3)  0           conv2d_22[0][0]
                                                                 input_2[0][0]
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 512, 512, 2)  56          concatenate_4[0][0]
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 512, 512, 1)  19          conv2d_23[0][0]
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 512, 512, 1)  2           conv2d_24[0][0]
==================================================================================================
Total params: 31,032,335
Trainable params: 31,032,335
Non-trainable params: 0
__________________________________________________________________________________________________
loading data
load train images...
------------------------------
load test images...
------------------------------
loading data done
(None, 512, 512, 2)
(None, 512, 512, 1)
got unet
Fitting model...
Epoch 1/50
2021-09-22 17:43:32.447700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cudnn64_7.dll
2021-09-22 17:43:33.185598: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking G
PU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-09-22 17:43:33.250487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully op
ened dynamic library cublas64_10.dll
  2/122 [..............................] - ETA: 33s - loss: 0.6959 - accuracy: 0.5922 - mse: 0.2513WARNING:
tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1770s vs
 `on_train_batch_end` time: 0.3818s). Check your callbacks.
122/122 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.7149 - mse: 0.2484
Epoch 00001: loss improved from inf to 0.68958, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 73s 595ms/step - loss: 0.6896 - accuracy: 0.7149 - mse: 0.2484 -
 val_loss: 0.6851 - val_accuracy: 0.7193 - val_mse: 0.2464
Epoch 2/50
122/122 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.7244 - mse: 0.2454
Epoch 00002: loss improved from 0.68958 to 0.68276, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 68s 555ms/step - loss: 0.6828 - accuracy: 0.7244 - mse: 0.2454 -
 val_loss: 0.6608 - val_accuracy: 0.7532 - val_mse: 0.2355
Epoch 3/50
122/122 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.8496 - mse: 0.2162
Epoch 00003: loss improved from 0.68276 to 0.61243, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 68s 554ms/step - loss: 0.6124 - accuracy: 0.8496 - mse: 0.2162 -
 val_loss: 0.6087 - val_accuracy: 0.9025 - val_mse: 0.2125
Epoch 4/50
122/122 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.8988 - mse: 0.2004
Epoch 00004: loss improved from 0.61243 to 0.57181, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 553ms/step - loss: 0.5718 - accuracy: 0.8988 - mse: 0.2004 -
 val_loss: 0.5989 - val_accuracy: 0.8739 - val_mse: 0.2085
Epoch 5/50
122/122 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.9081 - mse: 0.1954
Epoch 00005: loss improved from 0.57181 to 0.56017, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.5602 - accuracy: 0.9081 - mse: 0.1954 -
 val_loss: 0.5997 - val_accuracy: 0.9153 - val_mse: 0.2073
Epoch 6/50
122/122 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.9121 - mse: 0.1927
Epoch 00006: loss improved from 0.56017 to 0.55242, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.5524 - accuracy: 0.9121 - mse: 0.1927 -
 val_loss: 0.5662 - val_accuracy: 0.9179 - val_mse: 0.1950
Epoch 7/50
122/122 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.9203 - mse: 0.1878
Epoch 00007: loss improved from 0.55242 to 0.53949, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.5395 - accuracy: 0.9203 - mse: 0.1878 -
 val_loss: 0.5706 - val_accuracy: 0.9080 - val_mse: 0.1965
Epoch 8/50
122/122 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.9189 - mse: 0.1864
Epoch 00008: loss improved from 0.53949 to 0.53731, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.5373 - accuracy: 0.9189 - mse: 0.1864 -
 val_loss: 0.5600 - val_accuracy: 0.9123 - val_mse: 0.1914
Epoch 9/50
122/122 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.9258 - mse: 0.1818
Epoch 00009: loss improved from 0.53731 to 0.52458, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 553ms/step - loss: 0.5246 - accuracy: 0.9258 - mse: 0.1818 -
 val_loss: 0.5286 - val_accuracy: 0.9213 - val_mse: 0.1819
Epoch 10/50
122/122 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.9269 - mse: 0.1796
Epoch 00010: loss improved from 0.52458 to 0.52011, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.5201 - accuracy: 0.9269 - mse: 0.1796 -
 val_loss: 0.5302 - val_accuracy: 0.9204 - val_mse: 0.1818
Epoch 11/50
122/122 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.9296 - mse: 0.1768
Epoch 00011: loss improved from 0.52011 to 0.51296, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 68s 557ms/step - loss: 0.5130 - accuracy: 0.9296 - mse: 0.1768 -
 val_loss: 0.5562 - val_accuracy: 0.9021 - val_mse: 0.1892
Epoch 12/50
122/122 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.9303 - mse: 0.1747
Epoch 00012: loss improved from 0.51296 to 0.50871, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 69s 562ms/step - loss: 0.5087 - accuracy: 0.9303 - mse: 0.1747 -
 val_loss: 0.5149 - val_accuracy: 0.9234 - val_mse: 0.1757
Epoch 13/50
122/122 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.9330 - mse: 0.1719
Epoch 00013: loss improved from 0.50871 to 0.50173, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 69s 567ms/step - loss: 0.5017 - accuracy: 0.9330 - mse: 0.1719 -
 val_loss: 0.5130 - val_accuracy: 0.9230 - val_mse: 0.1742
Epoch 14/50
122/122 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.9348 - mse: 0.1694
Epoch 00014: loss improved from 0.50173 to 0.49572, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4957 - accuracy: 0.9348 - mse: 0.1694 -
 val_loss: 0.5062 - val_accuracy: 0.9254 - val_mse: 0.1718
Epoch 15/50
122/122 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.9324 - mse: 0.1687
Epoch 00015: loss did not improve from 0.49572
122/122 [==============================] - 66s 544ms/step - loss: 0.4959 - accuracy: 0.9324 - mse: 0.1687 -
 val_loss: 0.5044 - val_accuracy: 0.9224 - val_mse: 0.1708
Epoch 16/50
122/122 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.9365 - mse: 0.1653
Epoch 00016: loss improved from 0.49572 to 0.48711, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4871 - accuracy: 0.9365 - mse: 0.1653 -
 val_loss: 0.4956 - val_accuracy: 0.9274 - val_mse: 0.1671
Epoch 17/50
122/122 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.9371 - mse: 0.1635
Epoch 00017: loss improved from 0.48711 to 0.48364, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 68s 553ms/step - loss: 0.4836 - accuracy: 0.9371 - mse: 0.1635 -
 val_loss: 0.4974 - val_accuracy: 0.9272 - val_mse: 0.1672
Epoch 18/50
122/122 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.9328 - mse: 0.1632
Epoch 00018: loss did not improve from 0.48364
122/122 [==============================] - 66s 545ms/step - loss: 0.4854 - accuracy: 0.9328 - mse: 0.1632 -
 val_loss: 0.4945 - val_accuracy: 0.9219 - val_mse: 0.1658
Epoch 19/50
122/122 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.9393 - mse: 0.1594
Epoch 00019: loss improved from 0.48364 to 0.47502, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4750 - accuracy: 0.9393 - mse: 0.1594 -
 val_loss: 0.4823 - val_accuracy: 0.9294 - val_mse: 0.1613
Epoch 20/50
122/122 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.9430 - mse: 0.1563
Epoch 00020: loss improved from 0.47502 to 0.46706, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 550ms/step - loss: 0.4671 - accuracy: 0.9430 - mse: 0.1563 -
 val_loss: 0.4849 - val_accuracy: 0.9313 - val_mse: 0.1600
Epoch 21/50
122/122 [==============================] - ETA: 0s - loss: 0.4649 - accuracy: 0.9415 - mse: 0.1550
Epoch 00021: loss improved from 0.46706 to 0.46492, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4649 - accuracy: 0.9415 - mse: 0.1550 -
 val_loss: 0.4894 - val_accuracy: 0.9230 - val_mse: 0.1616
Epoch 22/50
122/122 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.9427 - mse: 0.1530
Epoch 00022: loss improved from 0.46492 to 0.46032, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4603 - accuracy: 0.9427 - mse: 0.1530 -
 val_loss: 0.4884 - val_accuracy: 0.9193 - val_mse: 0.1611
Epoch 23/50
122/122 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.9437 - mse: 0.1510
Epoch 00023: loss improved from 0.46032 to 0.45623, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4562 - accuracy: 0.9437 - mse: 0.1510 -
 val_loss: 0.4719 - val_accuracy: 0.9307 - val_mse: 0.1551
Epoch 24/50
122/122 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.9462 - mse: 0.1483
Epoch 00024: loss improved from 0.45623 to 0.44956, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 550ms/step - loss: 0.4496 - accuracy: 0.9462 - mse: 0.1483 -
 val_loss: 0.4615 - val_accuracy: 0.9340 - val_mse: 0.1515
Epoch 25/50
122/122 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.9470 - mse: 0.1464
Epoch 00025: loss improved from 0.44956 to 0.44520, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4452 - accuracy: 0.9470 - mse: 0.1464 -
 val_loss: 0.4664 - val_accuracy: 0.9326 - val_mse: 0.1522
Epoch 26/50
122/122 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.9483 - mse: 0.1442
Epoch 00026: loss improved from 0.44520 to 0.44024, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4402 - accuracy: 0.9483 - mse: 0.1442 -
 val_loss: 0.4543 - val_accuracy: 0.9363 - val_mse: 0.1477
Epoch 27/50
122/122 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.9473 - mse: 0.1431
Epoch 00027: loss improved from 0.44024 to 0.43843, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4384 - accuracy: 0.9473 - mse: 0.1431 -
 val_loss: 0.4503 - val_accuracy: 0.9352 - val_mse: 0.1461
Epoch 28/50
122/122 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.9482 - mse: 0.1411
Epoch 00028: loss improved from 0.43843 to 0.43411, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4341 - accuracy: 0.9482 - mse: 0.1411 -
 val_loss: 0.4469 - val_accuracy: 0.9378 - val_mse: 0.1440
Epoch 29/50
122/122 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.9495 - mse: 0.1390
Epoch 00029: loss improved from 0.43411 to 0.42950, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4295 - accuracy: 0.9495 - mse: 0.1390 -
 val_loss: 0.4460 - val_accuracy: 0.9342 - val_mse: 0.1438
Epoch 30/50
122/122 [==============================] - ETA: 0s - loss: 0.4244 - accuracy: 0.9507 - mse: 0.1369
Epoch 00030: loss improved from 0.42950 to 0.42436, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4244 - accuracy: 0.9507 - mse: 0.1369 -
 val_loss: 0.4387 - val_accuracy: 0.9370 - val_mse: 0.1412
Epoch 31/50
122/122 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.9508 - mse: 0.1354
Epoch 00031: loss improved from 0.42436 to 0.42130, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.4213 - accuracy: 0.9508 - mse: 0.1354 -
 val_loss: 0.4389 - val_accuracy: 0.9359 - val_mse: 0.1403
Epoch 32/50
122/122 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.9529 - mse: 0.1330
Epoch 00032: loss improved from 0.42130 to 0.41579, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4158 - accuracy: 0.9529 - mse: 0.1330 -
 val_loss: 0.4346 - val_accuracy: 0.9370 - val_mse: 0.1383
Epoch 33/50
122/122 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.9533 - mse: 0.1314
Epoch 00033: loss improved from 0.41579 to 0.41254, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4125 - accuracy: 0.9533 - mse: 0.1314 -
 val_loss: 0.4288 - val_accuracy: 0.9378 - val_mse: 0.1364
Epoch 34/50
122/122 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.9540 - mse: 0.1296
Epoch 00034: loss improved from 0.41254 to 0.40842, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4084 - accuracy: 0.9540 - mse: 0.1296 -
 val_loss: 0.4276 - val_accuracy: 0.9402 - val_mse: 0.1343
Epoch 35/50
122/122 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.9554 - mse: 0.1276
Epoch 00035: loss improved from 0.40842 to 0.40384, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.4038 - accuracy: 0.9554 - mse: 0.1276 -
 val_loss: 0.4236 - val_accuracy: 0.9386 - val_mse: 0.1333
Epoch 36/50
122/122 [==============================] - ETA: 0s - loss: 0.3999 - accuracy: 0.9562 - mse: 0.1258
Epoch 00036: loss improved from 0.40384 to 0.39990, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.3999 - accuracy: 0.9562 - mse: 0.1258 -
 val_loss: 0.4195 - val_accuracy: 0.9387 - val_mse: 0.1319
Epoch 37/50
122/122 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.9592 - mse: 0.1232
Epoch 00037: loss improved from 0.39990 to 0.39386, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.3939 - accuracy: 0.9592 - mse: 0.1232 -
 val_loss: 0.4142 - val_accuracy: 0.9423 - val_mse: 0.1290
Epoch 38/50
122/122 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.9585 - mse: 0.1220
Epoch 00038: loss improved from 0.39386 to 0.39184, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.3918 - accuracy: 0.9585 - mse: 0.1220 -
 val_loss: 0.4146 - val_accuracy: 0.9429 - val_mse: 0.1281
Epoch 39/50
122/122 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.9600 - mse: 0.1199
Epoch 00039: loss improved from 0.39184 to 0.38675, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.3868 - accuracy: 0.9600 - mse: 0.1199 -
 val_loss: 0.4101 - val_accuracy: 0.9437 - val_mse: 0.1259
Epoch 40/50
122/122 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.9607 - mse: 0.1182
Epoch 00040: loss improved from 0.38675 to 0.38288, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.3829 - accuracy: 0.9607 - mse: 0.1182 -
 val_loss: 0.4067 - val_accuracy: 0.9464 - val_mse: 0.1237
Epoch 41/50
122/122 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.9621 - mse: 0.1162
Epoch 00041: loss improved from 0.38288 to 0.37818, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.3782 - accuracy: 0.9621 - mse: 0.1162 -
 val_loss: 0.4016 - val_accuracy: 0.9442 - val_mse: 0.1228
Epoch 42/50
122/122 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.9568 - mse: 0.1173
Epoch 00042: loss did not improve from 0.37818
122/122 [==============================] - 66s 544ms/step - loss: 0.3833 - accuracy: 0.9568 - mse: 0.1173 -
 val_loss: 0.4032 - val_accuracy: 0.9391 - val_mse: 0.1237
Epoch 43/50
122/122 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.9603 - mse: 0.1142
Epoch 00043: loss improved from 0.37818 to 0.37465, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.3746 - accuracy: 0.9603 - mse: 0.1142 -
 val_loss: 0.4033 - val_accuracy: 0.9472 - val_mse: 0.1193
Epoch 44/50
122/122 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.9637 - mse: 0.1113
Epoch 00044: loss improved from 0.37465 to 0.36735, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 551ms/step - loss: 0.3674 - accuracy: 0.9637 - mse: 0.1113 -
 val_loss: 0.3976 - val_accuracy: 0.9465 - val_mse: 0.1183
Epoch 45/50
122/122 [==============================] - ETA: 0s - loss: 0.3629 - accuracy: 0.9649 - mse: 0.1094
Epoch 00045: loss improved from 0.36735 to 0.36289, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.3629 - accuracy: 0.9649 - mse: 0.1094 -
 val_loss: 0.3892 - val_accuracy: 0.9481 - val_mse: 0.1161
Epoch 46/50
122/122 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.9601 - mse: 0.1104
Epoch 00046: loss did not improve from 0.36289
122/122 [==============================] - 66s 544ms/step - loss: 0.3673 - accuracy: 0.9601 - mse: 0.1104 -
 val_loss: 0.3935 - val_accuracy: 0.9474 - val_mse: 0.1155
Epoch 47/50
122/122 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.9605 - mse: 0.1090
Epoch 00047: loss did not improve from 0.36289
122/122 [==============================] - 66s 543ms/step - loss: 0.3639 - accuracy: 0.9605 - mse: 0.1090 -
 val_loss: 0.3813 - val_accuracy: 0.9450 - val_mse: 0.1147
Epoch 48/50
122/122 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.9637 - mse: 0.1061
Epoch 00048: loss improved from 0.36289 to 0.35650, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 550ms/step - loss: 0.3565 - accuracy: 0.9637 - mse: 0.1061 -
 val_loss: 0.3778 - val_accuracy: 0.9495 - val_mse: 0.1118
Epoch 49/50
122/122 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.9650 - mse: 0.1042
Epoch 00049: loss improved from 0.35650 to 0.35227, saving model to ./weights\hs_v3_unet.hdf5
122/122 [==============================] - 67s 552ms/step - loss: 0.3523 - accuracy: 0.9650 - mse: 0.1042 -
 val_loss: 0.4019 - val_accuracy: 0.9324 - val_mse: 0.1194
Epoch 50/50
122/122 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.9440 - mse: 0.1131
Epoch 00050: loss did not improve from 0.35227
122/122 [==============================] - 66s 544ms/step - loss: 0.3793 - accuracy: 0.9440 - mse: 0.1131 -
 val_loss: 0.3860 - val_accuracy: 0.9368 - val_mse: 0.1153
predict test data
test candidate data : (20, 512, 512, 2)
 1/20 [>.............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end`
is slow compared to the batch time (batch time: 0.0030s vs `on_predict_batch_end` time: 0.0399s). Check you
r callbacks.
20/20 [==============================] - 1s 41ms/step
test result data : (20, 512, 512, 1)
array to image